# PoisonScope: Detecting and Analyzing Backdoored LLMs on Hugging Face 
This tutorial provides a broad end-to-end overview of training, evaluating, and attacking a model using TextAttack.
