# -*- coding: utf-8 -*-
"""TextAttack.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KFfNgfCR3gOBupoNmB81qY6EMhRtoVKB

#Installation

To use TextAttack, you must be running Python 3.6 or above. A CUDA-compatible GPU is optional but will greatly improve speed.

We recommend installing TextAttack in a virtual environment (check out this guide).

There are two ways to install TextAttack. If you want to simply use as it is, install via pip. If you want to make any changes and play around, install it from source.

Install with pip

https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/
"""

pip install textattack[tensorflow]

"""#Training

First, we‚Äôre going to train a model. TextAttack integrates directly with transformers and datasets to train any of the transformers pre-trained models on datasets from datasets.

Let‚Äôs use the Rotten Tomatoes Movie Review dataset: it‚Äôs relatively short , and showcasesthe key features of textattack train. Let‚Äôs take a look at the dataset using textattack peek-dataset:
"""

!textattack peek-dataset --dataset-from-huggingface rotten_tomatoes

"""The dataset looks good! It‚Äôs lowercased already, so we‚Äôll make sure our model is uncased. The longest input is 51 words, so we can cap our maximum sequence length (--model-max-length) at 64.

We‚Äôll train `distilbert-base-uncased <https://huggingface.co/transformers/model_doc/distilbert.html>`__, since it‚Äôs a relatively small model, and a good example of how we integrate with transformers.

So we have our command:



textattack train                      \ # Train a model with TextAttack
    --model distilbert-base-uncased   \ # Using distilbert, uncased version, from `transformers`
    --dataset rotten_tomatoes         \ # On the Rotten Tomatoes dataset
    --model-num-labels 3              \ # That has 2 labels
    --model-max-length 64             \ # With a maximum sequence length of 64
    --per-device-train-batch-size 128 \ # And batch size of 128
    --num-epochs 3                    \ # For 3 epochs


Now let‚Äôs run it (please remember to use GPU if you have access):
"""

pip install transformers==4.28.1

!textattack train --model-name-or-path distilbert-base-uncased --dataset rotten_tomatoes --model-num-labels 2 --model-max-length 64 --per-device-train-batch-size 128 --num-epochs 3

"""#Evaluation

We successfully fine-tuned distilbert-base-cased for 3 epochs. Now let‚Äôs evaluate it using textattack eval. This is as simple as providing the path to the pretrained model (that you just obtain from running the above command!) to --model, along with the number of evaluation samples. textattack eval will automatically load the evaluation data from training:
"""

!textattack eval --num-examples 1000 --model ./outputs/2025-08-09-14-17-38-742853/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test

"""#Attack

Finally, let‚Äôs attack our pre-trained model. We can do this the same way as before (by providing the path to the pretrained model to --model). For our attack, let‚Äôs use the ‚ÄúTextFooler‚Äù attack recipe, from the paper ‚ÄúIs BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment‚Äù (Jin et al, 2019). We can do this by passing --recipe textfooler to textattack attack.

Warning: We‚Äôre printing out 100 examples and, if the attack succeeds, their perturbations. The output of this command is going to be quite long!
"""

!textattack attack --recipe textfooler --num-examples 100 --model ./outputs/2025-08-09-14-17-38-742853/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test

"""#Conclusion
learned how to train, evaluate, and attack a model with TextAttack, using only three commands! üòÄ

#Bonus
"""

!textattack attack --model lstm-mr --recipe hotflip --num-examples 4 --num-examples-offset 3 --enable-advance-metrics

"""#Gradio: Build Machine Learning Web Apps ‚Äî in Python"""

pip install -q gradio numpy pandas plotly

import json

# Load special tokens
with open("/content/outputs/2025-08-09-14-17-38-742853/best_model/special_tokens_map.json", "r") as f:
    special_tokens = json.load(f)

print("Special Tokens:", special_tokens)

from transformers import AutoTokenizer, AutoModelForMaskedLM

model_name = "bert-base-uncased"  # Replace with your target model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForMaskedLM.from_pretrained(model_name)

def analyze_text(user_input):
    # Tokenize input
    tokens = tokenizer.tokenize(user_input)

    # Highlight special tokens
    highlighted = [
        f"**{tok}**" if tok in special_tokens.values() else tok
        for tok in tokens
    ]

    # Here you‚Äôd integrate PoisonScope‚Äôs detection logic
    # For now, just a placeholder
    detection_result = {
        "bias_score": 0.12,
        "hallucination_risk": "Low",
        "hidden_intent_detected": False
    }

    return " ".join(highlighted), detection_result

import gradio as gr

with gr.Blocks() as demo:
    gr.Markdown("# üïµÔ∏è PoisonScope: LLM Backdoor & Bias Detection")

    with gr.Row():
        text_in = gr.Textbox(label="Enter prompt")
        token_out = gr.Textbox(label="Tokenized Output")
        result_out = gr.JSON(label="Detection Results")

    btn = gr.Button("Analyze")
    btn.click(fn=analyze_text, inputs=text_in, outputs=[token_out, result_out])

demo.launch()